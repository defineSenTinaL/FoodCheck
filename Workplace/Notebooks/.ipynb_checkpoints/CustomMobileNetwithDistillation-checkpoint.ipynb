{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBfYjUMVrlbr"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3001,
     "status": "ok",
     "timestamp": 1657339645222,
     "user": {
      "displayName": "Dixit Prajapati",
      "userId": "16575914818580667927"
     },
     "user_tz": -330
    },
    "id": "bWYdKAJSrE6e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from shutil import copy\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential , load_model\n",
    "from tensorflow.keras.layers import Flatten , Dense , Conv2D , MaxPooling2D , Dropout , BatchNormalization , GlobalAveragePooling2D , DepthwiseConv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VwNfbEPr0F2"
   },
   "source": [
    "# Downloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1657339645222,
     "user": {
      "displayName": "Dixit Prajapati",
      "userId": "16575914818580667927"
     },
     "user_tz": -330
    },
    "id": "-1KaKJ3prmD-"
   },
   "outputs": [],
   "source": [
    "def get_data_extract():\n",
    "  if \"food-101\" in os.listdir():\n",
    "    print(\"Dataset already exists\")\n",
    "  else:\n",
    "    tf.keras.utils.get_file(\n",
    "    'food-101.tar.gz',\n",
    "    'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',\n",
    "    cache_subdir='/content',\n",
    "    extract=True,\n",
    "    archive_format='tar',\n",
    "    cache_dir=None\n",
    "    )\n",
    "    print(\"Dataset downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hg1dmXcar44p",
    "outputId": "41a72f19-4d5a-49af-dc30-367a8eededbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
      " 114630656/4996278331 [..............................] - ETA: 6:55"
     ]
    }
   ],
   "source": [
    "# Download data and extract it to folder\n",
    "get_data_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVpO1dcMr-Fw"
   },
   "outputs": [],
   "source": [
    "os.listdir(\"food-101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ht1WW9tur-Im"
   },
   "outputs": [],
   "source": [
    "os.listdir(\"food-101/meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SVqsIXMr-OQ"
   },
   "outputs": [],
   "source": [
    "print(f\"The No of Classes in Dataset are : {len(os.listdir('/content/food-101/images'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH_fcbXVr-R9"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for folder in os.listdir(\"food-101/images\"):\n",
    "  folder_path = os.path.join(\"food-101/images\" , folder)\n",
    "  print(f\"The No of Images of Class : {folder} in Dataset are : {len(os.listdir(folder_path))}\")\n",
    "  count = count + 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "759vNWedsHlt"
   },
   "source": [
    "#####Dataset Information\n",
    "\n",
    "This Dataset has 101 Classes with 1000 images for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8DRM9z_sJpj"
   },
   "source": [
    "\n",
    "\n",
    "# Splitting the Data into Training and Testing Data\n",
    "\n",
    "There are two files in meta folder train.txt and test.txt in which list of images is given which needed to be in training set and testing set\n",
    "\n",
    "* Training Set includes 750 images for each class\n",
    "* Testing Set incldes 250 images for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuLh9rxDr-Vu"
   },
   "outputs": [],
   "source": [
    "def prepare_data(filepath , src_file  , dest_file):\n",
    "  classes_images = dict()\n",
    "  for folder_name in os.listdir(src_file):\n",
    "    classes_images[folder_name] = []\n",
    "    \n",
    "\n",
    "  with open(filepath , 'r') as txt:\n",
    "    #Getting the paths for images\n",
    "    paths = [read.strip() for read in txt.readlines()]\n",
    "\n",
    "  for p in paths:\n",
    "    food = p.split(\"/\")\n",
    "    classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "\n",
    "  os.makedirs(dest_file , exist_ok = True)\n",
    "  \n",
    "  for food in classes_images.keys():\n",
    "    print(\"\\nCopying Images into \" , food)\n",
    "\n",
    "    if not os.path.exists(os.path.join(\"food\" , food)):\n",
    "      os.makedirs(os.path.join(dest_file , food))\n",
    "\n",
    "    for i in classes_images[food]:\n",
    "  \n",
    "      copy(os.path.join(src_file , food , i) , os.path.join( dest_file, food , i))\n",
    "      \n",
    "    print(f\"Copied {len(classes_images[food])} images into {food}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89x4tUFwsOTS"
   },
   "outputs": [],
   "source": [
    "# Testing Data\n",
    "prepare_data(\"/content/food-101/meta/test.txt\" ,\"/content/food-101/images\" , \"food/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBYsA68KsOXU"
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "prepare_data(\"/content/food-101/meta/train.txt\" , \"/content/food-101/images\" , \"food/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3zYu1q7Ln9_"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baANvm_G3mIW"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyNphwKTHaEi"
   },
   "outputs": [],
   "source": [
    "teacher_base_model = EfficientNetB4(weights = \"imagenet\", include_top  = False ,  classes = 101 , input_shape = (380 , 380 , 3))\n",
    "x = GlobalAveragePooling2D()(teacher_base_model.output)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "teacher_outputs = Dense(101 , activation = \"softmax\")(x)\n",
    "teacher_model = tf.keras.models.Model(teacher_base_model.input , teacher_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woSpBMCrEj6M"
   },
   "outputs": [],
   "source": [
    "teacher_model.load_weights(\"/content/drive/MyDrive/Computer Vision/Knowledge_distillation/Models (1)/EfficientNetTLmodel_v2.14.h5\")\n",
    "teacher_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ohL_yB7J_MY"
   },
   "outputs": [],
   "source": [
    "Teacher_clf_layer = teacher_model.layers[-1]\n",
    "Teacher_clf_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYT-OOv9KKje"
   },
   "outputs": [],
   "source": [
    "Teacher_clf_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXMhS8pPOydB"
   },
   "outputs": [],
   "source": [
    "teacher_model = tf.keras.Model(teacher_model.inputs, teacher_model.layers[-2].output, name='TeacherTransfer')\n",
    "# teacher_model = tf.keras.Model(teacher_model.inputs, teacher_model.layers[-3].output, name='TeacherScratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZ9jvFk_gtIH"
   },
   "outputs": [],
   "source": [
    "teacher_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjgTNRBER3Rq"
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(160, 160, 3), include_top=False, weights='imagenet')\n",
    "x = tf.keras.layers.Reshape(target_shape=(16, 20, 100))(base_model.output)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = tf.keras.layers.Conv2D(28, (1, 3), padding='valid', use_bias=False)(x)\n",
    "features  = tf.keras.layers.Flatten()(x)\n",
    "# Removing Dropout as you shouldnt have a dropout active on an output layer \n",
    "# x = tf.keras.layers.Dropout(0.1)(features)\n",
    "outputs = Dense(101 , activation = \"softmax\")(features)\n",
    "\n",
    "student_model = tf.keras.models.Model(base_model.input , outputs = [features , outputs])\n",
    "student_model.trainable = True\n",
    "\n",
    "# weights_path = \"/content/drive/MyDrive/Computer Vision/Knowledge_distillation/Models (1)/Student_mobileNetV2_model/MobileNetScratch.05.h5\"\n",
    "# student_model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3I7ivJViN7b"
   },
   "outputs": [],
   "source": [
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqZpXEg6KQ72"
   },
   "outputs": [],
   "source": [
    "student_model.layers[-1].set_weights(Teacher_clf_layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJiu8N3tKaXV"
   },
   "outputs": [],
   "source": [
    "student_model.layers[-1].weights[0] == Teacher_clf_layer.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_todSjrOHh-"
   },
   "outputs": [],
   "source": [
    "class Distill_model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, student, teacher, name=None):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.teacher.trainable = False\n",
    "\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "        self.logits_loss_tracker = tf.keras.metrics.Mean(name='logits_loss')\n",
    "        self.feature_loss_tracker = tf.keras.metrics.Mean(name='feature_loss')\n",
    "        self.acc_tracker = tf.keras.metrics.Mean(name='accuracy')\n",
    "\n",
    "        self.resize_input_for_student = tf.keras.layers.Resizing(160, 160)\n",
    "        self.loss_weight = 0.5\n",
    "        self.temperature = 3\n",
    "\n",
    "    def set_loss_weight(self, w = 0.5):\n",
    "        self.loss_weight = w\n",
    "\n",
    "    def set_temp(self, t = 3):\n",
    "        self.temperature = t\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        student_features, logits = self.student(inputs, training=training)        \n",
    "        return student_features, logits\n",
    "\n",
    "    def compute_loss(self, logits, student_features, labels, teacher_features, training = False):\n",
    "        logits_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n",
    "        \n",
    "        # feature_loss = tf.keras.losses.KLDivergence()(\n",
    "        #         (teacher_features / self.temperature),\n",
    "        #         (student_features / self.temperature))\n",
    "\n",
    "\n",
    "        # feature_loss = tf.keras.losses.CategoricalCrossentropy()(teacher_features, student_features)\n",
    "\n",
    "        feature_loss = tf.keras.losses.MeanSquaredError()(\n",
    "            (teacher_features / self.temperature), (student_features / self.temperature))\n",
    "\n",
    "        loss = self.loss_weight * logits_loss + (1 - self.loss_weight) * feature_loss\n",
    "\n",
    "        self.logits_loss_tracker.update_state(logits_loss)\n",
    "        self.feature_loss_tracker.update_state(feature_loss)\n",
    "        self.total_loss_tracker.update_state(loss)\n",
    "        self.acc_tracker.update_state(labels, logits)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "\n",
    "        images, labels = data\n",
    "\n",
    "        if images.shape[1:3] != (160, 160):\n",
    "            student_images = self.resize_input_for_student(images)\n",
    "        else:\n",
    "            student_images = images\n",
    "\n",
    "        student_features, logits = self(student_images)\n",
    "        teacher_features = self.teacher(images, training=False)\n",
    "        \n",
    "        train_variables = self.trainable_variables\n",
    "        loss = self.compute_loss(logits, student_features, labels, teacher_features, training = True)\n",
    "        \n",
    "        grads = tf.gradients(loss, train_variables)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(grads, train_variables))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        images, labels = data\n",
    "\n",
    "        if images.shape[1:3] != (160, 160):\n",
    "            student_images = self.resize_input_for_student(images)\n",
    "        else:\n",
    "            student_images = images\n",
    "\n",
    "        student_features, logits = self(student_images)\n",
    "        teacher_features = self.teacher(images, training=False)\n",
    "        \n",
    "        loss = self.compute_loss(logits, student_features, labels, teacher_features, training = False)\n",
    "\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1NRTi4zRxna"
   },
   "outputs": [],
   "source": [
    "model = Distill_model(student=student_model, \n",
    "                      teacher=teacher_model,\n",
    "                      name='Distill_MobileNet_with_Teacher_Transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgsDR6OLll4t"
   },
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 160, 160, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bds9mgW5eUyU"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qX6LaJhttKoo"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woH0GNICsOfL"
   },
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(\"/content/drive/MyDrive/Computer Vision/Knowledge_distillation/Models\")\n",
    "# os.makedirs(ckpt_path , exist_ok = True)\n",
    "\n",
    "my_callbacks = [EarlyStopping(patience = 3) ,\n",
    "                ModelCheckpoint(os.path.join(ckpt_path, \"MobileNet_Student_Distill_TL_{epoch:02d}.h5\"), save_weights_only = True, save_best_only=False, verbose=1),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, verbose=1, min_delta=0.01)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDP_Jeeuyl7v"
   },
   "source": [
    "### Data Augementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yOqjEc1tOuI"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                             rotation_range = 180,\n",
    "                             shear_range = 0.2,\n",
    "                             zoom_range = 0.2,\n",
    "                             horizontal_flip = True ,\n",
    "                             vertical_flip = True,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             validation_split=0.2 ,\n",
    "                             rescale = 1./255\n",
    "                             \n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bx-EQ00YyrGa"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"/content/food/train\" , \n",
    "    target_size = (380 , 380),\n",
    "    class_mode = \"categorical\" ,\n",
    "    batch_size = 64\n",
    "\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"/content/food/test\" , \n",
    "    target_size = (380 , 380),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = 64,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ygq6qcpIhAc"
   },
   "source": [
    "# Distilling with Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-me3E7Hqmae"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer = opt)\n",
    "model.set_loss_weight(0.5)\n",
    "model.set_temp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfRz06TTyrXT"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 10,\n",
    "                    callbacks  = my_callbacks,\n",
    "                    validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGhn4pgMo_Bm"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/MyDrive/Computer Vision/Knowledge_distillation/Models/MobileNet_Student_Distill_TS_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWAkXdf9nM3Y"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer = opt)\n",
    "model.set_loss_weight(0.8)\n",
    "model.set_temp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3zoOrIGrLUm"
   },
   "source": [
    "1.3606  0.5254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZRT-WfGqCeS"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 10,\n",
    "                    callbacks  = my_callbacks,\n",
    "                    validation_data = test_generator,\n",
    "                    initial_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5-MGamR5SjQ"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/MyDrive/Computer Vision/Knowledge_distillation/Models/MobileNet_Student_Distill_TS_V2_03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVRDFmn55ERJ"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer = opt)\n",
    "model.set_loss_weight(0.8)\n",
    "model.set_temp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNyQfhiU6G_J"
   },
   "source": [
    "\n",
    "4/1184 - loss: 1.0236 - logits_loss: 1.1696 - feature_loss: 0.4396 - accuracy: 0.5681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wysXIjTLqIPM"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 10,\n",
    "                    callbacks  = my_callbacks,\n",
    "                    validation_data = test_generator,\n",
    "                    initial_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJ5wcof95HDZ"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 15,\n",
    "                    callbacks  = my_callbacks,\n",
    "                    validation_data = test_generator,\n",
    "                    initial_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67TKdWWvbaIo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VX5OhBSIlZ0"
   },
   "source": [
    "# Distilling with TL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSAN_iAN5gPt"
   },
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98wuxGC9InCI"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer = opt)\n",
    "model.set_loss_weight(0.5)\n",
    "model.set_temp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziuDuXVHL_yE"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUZwJY_pM7i8"
   },
   "source": [
    "Epoch 1/3\n",
    "  26/1184 [..............................] - ETA: 43:22 - loss: 4.1153 - logits_loss: 7.9638 - feature_loss: 0.2668 - accuracy: 0.0090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lx8ffdHVIwx2"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 3,\n",
    "                    callbacks  = my_callbacks,\n",
    "                    validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqT69cQg5tER"
   },
   "source": [
    " Did not work --> acc = 1.5%, slightly higher than random guessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUmXTql55d5D"
   },
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVETh6IK5zyM"
   },
   "source": [
    "Changing feature loss to MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tR8T_aUfI8G7"
   },
   "outputs": [],
   "source": [
    "images = next(train_generator)[0]\n",
    "teacher_features = model.teacher(images)\n",
    "student_features, logits = model.student(model.resize_input_for_student(images))\n",
    "\n",
    "tf.keras.losses.MeanSquaredError()(teacher_features, student_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGNxaOvb5pcZ"
   },
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(\"/content/drive/MyDrive/Computer Vision/Knowledge_distillation/Models\")\n",
    "# os.makedirs(ckpt_path , exist_ok = True)\n",
    "\n",
    "my_callbacks = [EarlyStopping(patience = 3) ,\n",
    "                ModelCheckpoint(os.path.join(ckpt_path, \"MobileNet_Student_Distill_TL_v2_{epoch:02d}.h5\"), save_weights_only = True, save_best_only=False, verbose=1),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, verbose=1, min_delta=0.01)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxrrvXf2L-PP"
   },
   "source": [
    "### .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0lck-U54zfz"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer = opt)\n",
    "model.set_loss_weight(0.5)\n",
    "model.set_temp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFtZOGJr6FGX"
   },
   "source": [
    "Epoch 1/3\n",
    "   7/1184 [..............................] - ETA: 44:18 - loss: 5.5273 - logits_loss: 5.7333 - feature_loss: 5.3214 - accuracy: 0.0092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQBwrQDZ5jcC"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 3,\n",
    "                    callbacks  = my_callbacks,\n",
    "                    validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5pq9tt7MCn9"
   },
   "source": [
    "### .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAKhyYeoGwNo"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer = opt)\n",
    "model.set_loss_weight(0.9)\n",
    "model.set_temp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMe7fPXRGQXj"
   },
   "outputs": [],
   "source": [
    "# model.load_weights('/content/drive/MyDrive/Computer Vision/Knowledge_distillation/Models/MobileNet_Student_Distill_TL_v2_01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vv1bXFqc6Dou"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 5,\n",
    "                    callbacks = my_callbacks,\n",
    "                    validation_data = test_generator,\n",
    "                    initial_epoch = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9OQZ0MYMEmd"
   },
   "source": [
    "### .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWFZCh5mDr8_"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/MyDrive/Computer Vision/Knowledge_distillation/Models (1)/MobileNet_Student_Distill_TL_05.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1ltKmSeGxiq"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer = opt)\n",
    "model.set_loss_weight(0.9)\n",
    "model.set_temp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgMekGJcDO8t"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 10,\n",
    "                    callbacks = my_callbacks,\n",
    "                    validation_data = test_generator,\n",
    "                    initial_epoch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHh6spTQD3ul"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 18,\n",
    "                    callbacks = my_callbacks,\n",
    "                    validation_data = test_generator,\n",
    "                    initial_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQ_YeaWxdp-v"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs = 22,\n",
    "                    callbacks = my_callbacks,\n",
    "                    validation_data = test_generator,\n",
    "                    initial_epoch = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZqcMmWe7DXj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3VwNfbEPr0F2",
    "g8DRM9z_sJpj",
    "7ygq6qcpIhAc",
    "hSAN_iAN5gPt"
   ],
   "name": "CustomMobileNetwithDistillation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
